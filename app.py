import streamlit as st
from audio_recorder_streamlit import audio_recorder
import whisper
import tempfile
import os

# 1. C·∫•u h√¨nh trang
st.set_page_config(page_title="Whisper Note", page_icon="üß†")
st.title("üß† Ghi Ch√∫ Th√¥ng Minh v·ªõi OpenAI Whisper")

# 2. Kh·ªüi t·∫°o Session State
if 'notes' not in st.session_state:
    st.session_state.notes = []

# 3. T·∫£i m√¥ h√¨nh Whisper (QUAN TR·ªåNG: D√πng Cache)
# Ch√∫ng ta d√πng @st.cache_resource ƒë·ªÉ ch·ªâ t·∫£i m√¥ h√¨nh 1 l·∫ßn duy nh·∫•t
# gi√∫p ·ª©ng d·ª•ng kh√¥ng b·ªã ch·∫≠m khi t·∫£i l·∫°i trang.
@st.cache_resource
def load_whisper_model():
    # "base" l√† m√¥ h√¨nh c√¢n b·∫±ng gi·ªØa t·ªëc ƒë·ªô v√† ƒë·ªô ch√≠nh x√°c.
    # B·∫°n c√≥ th·ªÉ ƒë·ªïi th√†nh "tiny" (nhanh h∆°n, k√©m h∆°n) ho·∫∑c "small" (ch·∫≠m h∆°n, t·ªët h∆°n)
    model = whisper.load_model("base")
    return model

# Hi·ªÉn th·ªã th√¥ng b√°o ƒëang t·∫£i model (ch·ªâ hi·ªán l·∫ßn ƒë·∫ßu)
with st.spinner("ƒêang t·∫£i m√¥ h√¨nh AI... Vui l√≤ng ƒë·ª£i gi√¢y l√°t"):
    model = load_whisper_model()

# 4. H√†m x·ª≠ l√Ω √¢m thanh v·ªõi Whisper
def transcribe_audio(audio_bytes):
    # Whisper c·∫ßn ƒë·ªçc t·ª´ file, kh√¥ng ƒë·ªçc tr·ª±c ti·∫øp t·ª´ bytes ƒë∆∞·ª£c
    # N√™n ta t·∫°o m·ªôt file t·∫°m th·ªùi
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_audio:
        temp_audio.write(audio_bytes)
        temp_filename = temp_audio.name

    try:
        # G·ªçi m√¥ h√¨nh ƒë·ªÉ nh·∫≠n di·ªán
        result = model.transcribe(temp_filename, language="vi")
        return result["text"]
    except Exception as e:
        return f"L·ªói: {e}"
    finally:
        # D·ªçn d·∫πp: X√≥a file t·∫°m sau khi d√πng xong
        if os.path.exists(temp_filename):
            os.remove(temp_filename)

# 5. Giao di·ªán ghi √¢m
st.write("Nh·∫•n micro ƒë·ªÉ ghi √¢m (M√¥ h√¨nh Base c√≥ th·ªÉ m·∫•t v√†i gi√¢y ƒë·ªÉ x·ª≠ l√Ω).")
audio_bytes = audio_recorder(
    text="",
    recording_color="#ff4b4b",
    neutral_color="#333333",
    icon_name="microphone",
    icon_size="2x",
)

# 6. X·ª≠ l√Ω logic khi c√≥ √¢m thanh
if audio_bytes:
    st.audio(audio_bytes, format="audio/wav")
    
    with st.spinner("AI ƒëang nghe v√† ph√¢n t√≠ch..."):
        transcript = transcribe_audio(audio_bytes)
        
        if transcript:
            st.success("Ho√†n t·∫•t!")
            st.subheader("üìù N·ªôi dung:")
            st.info(transcript)
            
            # L∆∞u v√†o l·ªãch s·ª≠ (tr√°nh l∆∞u tr√πng l·∫∑p n·∫øu app reload)
            if not st.session_state.notes or st.session_state.notes[-1] != transcript:
                st.session_state.notes.append(transcript)

# 7. Hi·ªÉn th·ªã l·ªãch s·ª≠
st.divider()
st.header("L·ªãch s·ª≠ Ghi ch√∫")
if st.session_state.notes:
    for i, note in enumerate(reversed(st.session_state.notes)):
        st.markdown(f"**Ghi ch√∫ {len(st.session_state.notes) - i}:**")
        st.write(note)
        st.markdown("---")
else:
    st.caption("Ch∆∞a c√≥ ghi ch√∫ n√†o.")
